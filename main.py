import time
import re
import os
import traceback
from datetime import datetime, timedelta
import pytz
from ics import Calendar, Event

# Selenium ç›¸å…³
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

def get_driver():
    options = Options()
    options.add_argument("--headless=new") 
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--remote-debugging-port=9222")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    chrome_binary_path = os.environ.get("CHROME_PATH")
    if chrome_binary_path:
        options.binary_location = chrome_binary_path

    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        return driver
    except Exception as e:
        print(f"æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def parse_day_content(html_content, current_date):
    """
    ç²¾å‡†è§£æï¼šåˆ©ç”¨ | åˆ†éš”ç¬¦è¿˜åŸè¡¨æ ¼ç»“æ„ï¼Œæå–ç»æµæ•°æ®å’Œè´¢ç»å¤§äº‹
    """
    events = []
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # æ ¸å¿ƒæŠ€å·§ï¼šä½¿ç”¨ | ä½œä¸ºåˆ†éš”ç¬¦æå–æ–‡æœ¬ï¼Œè¿™æ ·èƒ½ä¿ç•™è¡¨æ ¼çš„åˆ—ç»“æ„
    # ä¾‹å¦‚ï¼š "20:30|ç¾å›½|CPIå¹´ç‡|3.4%|3.2%|--"
    raw_text = soup.get_text("|", strip=True)
    lines = raw_text.split("|")
    
    # é‡ç»„é€»è¾‘ï¼šå› ä¸º split('|') ä¼šæŠŠæ‰€æœ‰å•å…ƒæ ¼æ‰“æ•£æˆä¸€ä¸ªå·¨å¤§çš„åˆ—è¡¨
    # æˆ‘ä»¬éœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡æ¥â€œæ‹¼å‡‘â€å‡ºæ¯ä¸€è¡Œ
    
    # çŠ¶æ€æœºæ¨¡å¼
    mode = "UNKNOWN" # UNKNOWN, DATA (ç»æµæ•°æ®), EVENT (è´¢ç»å¤§äº‹)
    
    # ä¸´æ—¶ç¼“å†²åŒºï¼Œç”¨äºå­˜å‚¨æ­£åœ¨æ‹¼å‡‘çš„ä¸€è¡Œæ•°æ®
    buffer_row = []
    
    print(f"  æ­£åœ¨åˆ†æé¡µé¢ç»“æ„...")

    # ä¸ºäº†æ›´ç²¾å‡†ï¼Œæˆ‘ä»¬ç›´æ¥æŸ¥æ‰¾åŒ…å«ç‰¹å®šå…³é”®è¯çš„å®¹å™¨è¡Œ
    # é‡‘åçš„æ¯ä¸€è¡Œé€šå¸¸æ˜¯ä¸€ä¸ª div æˆ–è€… tr
    rows = soup.find_all(['div', 'tr', 'li'])
    
    processed_hashes = set() # ç”¨äºå»é‡

    for row in rows:
        row_str = row.get_text("|", strip=True)
        
        # 1. æ¨¡å¼åˆ‡æ¢æ£€æµ‹
        if "ç»æµæ•°æ®ä¸€è§ˆ" in row_str and len(row_str) < 20:
            mode = "DATA"
            print("    -> åˆ‡æ¢åˆ° [ç»æµæ•°æ®] æ¨¡å¼")
            continue
        elif "è´¢ç»å¤§äº‹ä¸€è§ˆ" in row_str and len(row_str) < 20:
            mode = "EVENT"
            print("    -> åˆ‡æ¢åˆ° [è´¢ç»å¤§äº‹] æ¨¡å¼")
            continue
        elif "æœŸè´§æ—¥å†" in row_str or "ä¼‘å¸‚æ—¥å†" in row_str:
            mode = "UNKNOWN"
            continue
            
        if mode == "UNKNOWN":
            continue

        # 2. æ•°æ®è¡Œè¯†åˆ«
        # å°†è¡Œæ–‡æœ¬æ‹†åˆ†ä¸ºåˆ—
        cols = [c.strip() for c in row_str.split('|') if c.strip()]
        
        if not cols: continue

        # ç‰¹å¾è¯†åˆ«ï¼šç¬¬ä¸€åˆ—å¿…é¡»æ˜¯æ—¶é—´ (HH:MM)
        # ä¸”è¯¥è¡Œä¸èƒ½åŒ…å«è¡¨å¤´å…³é”®è¯ "å‰å€¼", "é¢„æµ‹å€¼", "é‡è¦æ€§"
        if not re.match(r'^\d{2}:\d{2}$', cols[0]):
            continue
        if any(h in row_str for h in ["å‰å€¼", "é¢„æµ‹å€¼", "å…¬å¸ƒå€¼", "äº‹ä»¶", "åœ°åŒº"]):
            continue

        # ç®€å•å»é‡ï¼šå› ä¸ºDOMç»“æ„åµŒå¥—ï¼ŒåŒä¸€è¡Œæ•°æ®å¯èƒ½è¢«çˆ¶çº§divå’Œå­çº§divåˆ†åˆ«è¯»å–ä¸€æ¬¡
        row_hash = hash(row_str)
        if row_hash in processed_hashes:
            continue
        processed_hashes.add(row_hash)

        # --- å¤„ç† [ç»æµæ•°æ®] ---
        if mode == "DATA":
            # ç†æƒ³åˆ—ç»“æ„: æ—¶é—´ | åœ°åŒº | æŒ‡æ ‡å | (æ˜Ÿæ˜Ÿ/é‡è¦æ€§) | å‰å€¼ | é¢„æµ‹å€¼ | å…¬å¸ƒå€¼
            # å®é™…æŠ“å–å¯èƒ½æœ‰æ‰€æ³¢åŠ¨ï¼Œæˆ‘ä»¬æ ¹æ®é•¿åº¦å’Œå†…å®¹æ¥æ˜ å°„
            
            time_str = cols[0]
            country = cols[1] if len(cols) > 1 else "å…¨çƒ"
            name = cols[2] if len(cols) > 2 else "æœªçŸ¥æŒ‡æ ‡"
            
            # æå–æ•°å€¼ï¼šä»åå¾€å‰æ‰¾ï¼Œé€šå¸¸æœ€åä¸‰åˆ—æ˜¯ [å‰å€¼, é¢„æµ‹, å…¬å¸ƒ] çš„å„ç§ç»„åˆ
            # é‡‘åé€šå¸¸é¡ºåºï¼šå‰å€¼ | é¢„æµ‹ | å…¬å¸ƒ
            # æˆ–è€…æ˜¯ï¼šå…¬å¸ƒ | é¢„æµ‹ | å‰å€¼ (å–å†³äºæŠ“å–é¡ºåºï¼Œé€šå¸¸ bs4 æ˜¯æŒ‰é˜…è¯»é¡ºåº)
            
            # ç­–ç•¥ï¼šå–åˆ—è¡¨æœ€å3ä¸ªå…ƒç´ ä½œä¸ºæ•°å€¼å€™é€‰
            potential_values = cols[-3:] 
            
            # åˆå§‹åŒ–
            prev, forecast, actual = "--", "--", "--"
            
            # åªæœ‰å½“åˆ—æ•°è¶³å¤Ÿå¤šæ—¶æ‰å°è¯•è§£ææ•°å€¼
            if len(cols) >= 5:
                # å‡è®¾æ ‡å‡†æƒ…å†µ: Time, Country, Name, ..., Prev, Forecast, Actual
                if len(potential_values) == 3:
                    prev = potential_values[0]
                    forecast = potential_values[1]
                    actual = potential_values[2]
                elif len(potential_values) == 2:
                    prev = potential_values[0]
                    forecast = potential_values[1]
            
            # è¿‡æ»¤æ‰éæ•°å€¼çš„å¹²æ‰°é¡¹ï¼ˆæ¯”å¦‚æŠŠæŒ‡æ ‡åå½“æˆäº†å‰å€¼ï¼‰
            # ç®€å•çš„å¯å‘å¼è¿‡æ»¤: æ•°å€¼åˆ—é€šå¸¸æ¯”è¾ƒçŸ­ï¼Œä¸”åŒ…å«æ•°å­—æˆ– % æˆ– --
            def is_value(s): return len(s) < 15 and (re.search(r'\d', s) or '--' in s)
            
            if not is_value(prev): prev = "--"
            if not is_value(forecast): forecast = "--"
            if not is_value(actual): actual = "--"

            # åˆ›å»ºæ—¥å†äº‹ä»¶
            evt = Event()
            evt.name = f"ğŸ“Š[{country}] {name}"
            
            hm = time_str.split(':')
            start_dt = datetime(
                current_date.year, current_date.month, current_date.day,
                int(hm[0]), int(hm[1]), tzinfo=pytz.timezone('Asia/Shanghai')
            )
            evt.begin = start_dt
            evt.duration = timedelta(minutes=15)
            
            evt.description = (
                f"ã€ç»æµæ•°æ®ã€‘\n"
                f"å›½å®¶: {country}\n"
                f"æŒ‡æ ‡: {name}\n"
                f"------------------\n"
                f"å‰å€¼: {prev}\n"
                f"é¢„æµ‹: {forecast}\n"
                f"å…¬å¸ƒ: {actual}\n"
            )
            events.append(evt)
            print(f"    [æ•°æ®] {time_str} {name} (å‰:{prev} é¢„:{forecast} å…¬:{actual})")

        # --- å¤„ç† [è´¢ç»å¤§äº‹] ---
        elif mode == "EVENT":
            # ç†æƒ³åˆ—ç»“æ„: æ—¶é—´ | åœ°åŒº | åŸå¸‚/é‡è¦æ€§ | äº‹ä»¶å†…å®¹
            time_str = cols[0]
            country = cols[1] if len(cols) > 1 else ""
            
            # åˆå¹¶å‰©ä½™åˆ—ä½œä¸ºäº‹ä»¶è¯¦æƒ…
            content = " ".join(cols[2:])
            
            evt = Event()
            # æ ‡é¢˜æˆªå–å‰20å­—
            title_text = content[:20] + "..." if len(content) > 20 else content
            evt.name = f"ğŸ“¢[{country}] {title_text}"
            
            hm = time_str.split(':')
            start_dt = datetime(
                current_date.year, current_date.month, current_date.day,
                int(hm[0]), int(hm[1]), tzinfo=pytz.timezone('Asia/Shanghai')
            )
            evt.begin = start_dt
            evt.duration = timedelta(minutes=30)
            
            evt.description = (
                f"ã€è´¢ç»å¤§äº‹ã€‘\n"
                f"å›½å®¶: {country}\n"
                f"æ—¶é—´: {time_str}\n"
                f"äº‹ä»¶è¯¦æƒ…: {content}\n"
            )
            events.append(evt)
            print(f"    [å¤§äº‹] {time_str} {title_text}")

    return events

def run_scraper():
    cal = Calendar()
    driver = get_driver()
    if not driver:
        exit(1)

    try:
        base_url = "https://qihuo.jin10.com/calendar.html#/"
        today = datetime.now(pytz.timezone('Asia/Shanghai')).date()
        
        # æŠ“å–èŒƒå›´ï¼šä»Šå¤© + æœªæ¥ 7 å¤©
        # å¦‚æœä½ æƒ³æµ‹è¯•é‚£4ä¸ªç‰¹å®šæ—¥æœŸï¼Œå¯ä»¥åœ¨è¿™é‡Œæ‰‹åŠ¨ä¿®æ”¹ target_date
        days_to_scrape = 8 
        total_count = 0

        for i in range(days_to_scrape):
            target_date = today + timedelta(days=i)
            date_str = target_date.strftime('%Y-%m-%d')
            full_url = f"{base_url}{date_str}"
            
            print(f"\n[{i+1}/{days_to_scrape}] æŠ“å–: {full_url}")
            
            try:
                driver.get(full_url)
                # é¡µé¢åŠ è½½ç­‰å¾… 6 ç§’
                time.sleep(6) 
                
                html = driver.page_source
                day_events = parse_day_content(html, target_date)
                
                for e in day_events:
                    cal.events.add(e)
                    total_count += 1
                
                if not day_events:
                    print("    (æ— æ•°æ®æˆ–æŠ“å–è¢«æ‹¦æˆª)")

            except Exception as e:
                print(f"    ! é¡µé¢å‡ºé”™: {e}")

    except Exception as e:
        print(f"å…¨å±€é”™è¯¯: {traceback.format_exc()}")
    finally:
        driver.quit()

    # ä¿å­˜
    if total_count > 0:
        output_file = 'jin10_calendar.ics'
        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(cal.serialize())
        print(f"\nç”ŸæˆæˆåŠŸ: {output_file} (åŒ…å« {total_count} æ¡æ•°æ®)")
    else:
        print("\næœªæŠ“å–åˆ°ä»»ä½•æ•°æ®ã€‚")

if __name__ == "__main__":
    run_scraper()
