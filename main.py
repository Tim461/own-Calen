import time
import re
import os
import traceback
from datetime import datetime, timedelta
import pytz
from ics import Calendar, Event

# Selenium ç›¸å…³
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# --- æŒ‡å®šä½ è¦æŠ“å–çš„è¿™4ä¸ªæ—¥æœŸ ---
TARGET_DATES = [
    "2026-01-14",
    "2026-01-15",
    "2026-01-16",
    "2026-01-20"
]
# -----------------------------

def get_driver():
    options = Options()
    options.add_argument("--headless=new") 
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--remote-debugging-port=9222")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    chrome_binary_path = os.environ.get("CHROME_PATH")
    if chrome_binary_path:
        options.binary_location = chrome_binary_path

    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        return driver
    except Exception as e:
        print(f"æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def is_value_column(text):
    """åˆ¤æ–­ä¸€åˆ—æ˜¯å¦åƒæ˜¯ä¸€ä¸ªæ•°å€¼ï¼ˆå‰å€¼/é¢„æµ‹/å…¬å¸ƒï¼‰"""
    # ç‰¹å¾ï¼šé•¿åº¦çŸ­ï¼ŒåŒ…å«æ•°å­—ï¼Œæˆ–è€…å°±æ˜¯ '--'
    # æ’é™¤çº¯æ–‡å­—ï¼ˆé™¤éæ˜¯éå¸¸çŸ­çš„çŠ¶æ€æè¿°ï¼‰
    if len(text) > 15: return False # æ•°å€¼é€šå¸¸ä¸ä¼šè¿™ä¹ˆé•¿
    if "--" in text: return True
    if re.search(r'\d', text): return True # åŒ…å«æ•°å­—
    if text in ["å¾…å®š", "æ— ", "ä¼‘å¸‚"]: return True
    return False

def parse_day_content(html_content, current_date):
    events = []
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # æŸ¥æ‰¾æ‰€æœ‰è¡Œå®¹å™¨
    rows = soup.find_all(['div', 'tr', 'li'])
    
    mode = "UNKNOWN"
    processed_hashes = set()

    for row in rows:
        # ä½¿ç”¨ | åˆ†å‰²ä¿æŒåˆ—ç»“æ„
        row_str = row.get_text("|", strip=True)
        
        # å»é‡
        h = hash(row_str)
        if h in processed_hashes: continue
        processed_hashes.add(h)

        # 1. è¯†åˆ« ã€ç»æµæ•°æ®ä¸€è§ˆã€‘ æ¿å—
        if "ç»æµæ•°æ®ä¸€è§ˆ" in row_str and len(row_str) < 30:
            mode = "DATA"
            print(f"  -> è¿›å…¥ [ç»æµæ•°æ®] åŒºåŸŸ")
            continue
        elif "è´¢ç»å¤§äº‹ä¸€è§ˆ" in row_str or "æœŸè´§æ—¥å†" in row_str:
            # é‡åˆ°å…¶ä»–æ¿å—ï¼Œç«‹å³åœæ­¢ï¼Œé˜²æ­¢æ··æ·†
            mode = "OTHER" 
            continue
            
        # æˆ‘ä»¬åªå…³å¿ƒ DATA æ¨¡å¼ï¼Œä¸”è¡Œé‡Œä¸èƒ½æœ‰è¡¨å¤´
        if mode != "DATA": continue
        if "æ—¶é—´" in row_str and "å‰å€¼" in row_str: continue

        # 2. æ‹†åˆ†åˆ—
        cols = [c.strip() for c in row_str.split('|') if c.strip()]
        if not cols: continue

        # è¿‡æ»¤ï¼šç¬¬ä¸€åˆ—å¿…é¡»æ˜¯æ—¶é—´ HH:MM
        if not re.match(r'^\d{2}:\d{2}$', cols[0]): continue

        # === æ ¸å¿ƒé€»è¾‘ï¼šä¸‰æ®µå¼å¤¹å‡»æ³• ===
        # ç›®æ ‡ï¼šæå– [æ—¶é—´, å›½å®¶, æŒ‡æ ‡åç§°, (é‡è¦æ€§), å‰å€¼, é¢„æµ‹, å…¬å¸ƒ]
        
        # A. å®šå·¦è¾¹ (Left Anchor)
        # cols[0] è‚¯å®šæ˜¯ æ—¶é—´
        # cols[1] é€šå¸¸æ˜¯ å›½å®¶ (å¦‚æœç¼ºå¤±å¯èƒ½ç›´æ¥æ˜¯åå­—ï¼Œä½†é‡‘åé€šå¸¸éƒ½æœ‰å›½å®¶)
        time_str = cols[0]
        country = cols[1]
        
        # B. å®šå³è¾¹ (Right Anchor)
        # ä»æœ€åçš„ä¸€åˆ—å¾€å›çœ‹ï¼Œæ”¶é›†æ‰€æœ‰çš„â€œæ•°å€¼åˆ—â€
        # æˆ‘ä»¬é¢„æœŸæœ€å¤šæ‰¾3ä¸ªæ•°å€¼ (å…¬å¸ƒ, é¢„æµ‹, å‰å€¼)
        values_found = [] # å­˜ [å…¬å¸ƒ, é¢„æµ‹, å‰å€¼] (å€’åº)
        
        # ä»åˆ—è¡¨æœ«å°¾å¼€å§‹å‘å‰æ‰«æ
        scan_index = len(cols) - 1
        while scan_index > 1: # ä¹Ÿå°±æ˜¯ä¸èƒ½æ‰«åˆ°å›½å®¶é‚£ä¸€åˆ—
            val = cols[scan_index]
            if is_value_column(val):
                values_found.append(val)
                scan_index -= 1
            else:
                # ä¸€æ—¦é‡åˆ°ä¸€ä¸ªä¸åƒæ•°å€¼çš„ä¸œè¥¿ï¼ˆå¤§æ¦‚ç‡æ˜¯æŒ‡æ ‡åç§°çš„æœ«å°¾ï¼Œæˆ–è€…é‡è¦æ€§ï¼‰ï¼Œåœæ­¢æ‰«æ
                break
        
        # è¿˜åŸæ•°å€¼é¡ºåº (å‰å€¼, é¢„æµ‹, å…¬å¸ƒ)
        # ç°åœ¨çš„ values_found æ˜¯å€’åºçš„ï¼Œä¾‹å¦‚ ['3.4%', '3.5%', '3.6%'] -> å¯¹åº” [å…¬å¸ƒ, é¢„æµ‹, å‰å€¼]
        # æˆ–è€… ['--', '3.5%', '3.6%']
        
        prev, forecast, actual = "--", "--", "--"
        
        # æ ¹æ®æ‰¾åˆ°çš„æ•°å€¼æ•°é‡è¿›è¡Œå¡«å……
        # é‡‘åçš„æ ‡å‡†é¡ºåºæ˜¯: ... å‰å€¼ | é¢„æµ‹ | å…¬å¸ƒ
        if len(values_found) >= 1: actual = values_found[0]
        if len(values_found) >= 2: forecast = values_found[1]
        if len(values_found) >= 3: prev = values_found[2]
        
        # C. å‰©ä¸­é—´ (The Indicator Name)
        # ä¸­é—´çš„éƒ¨åˆ†å°±æ˜¯ï¼šä» Country ä¹‹å (index 2)ï¼Œåˆ° values_found ä¹‹å‰ (scan_index)
        # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½åŒ…å«â€œé‡è¦æ€§â€ï¼ˆæ˜Ÿæ˜Ÿï¼‰ï¼Œé€šå¸¸è¡¨ç°ä¸ºç©ºç™½å­—ç¬¦æˆ–è€…"é«˜/ä¸­/ä½"æ–‡å­—
        # æˆ‘ä»¬æŠŠä¸­é—´å‰©ä¸‹çš„æ‰€æœ‰æ–‡æœ¬æ‹¼èµ·æ¥ï¼Œå°±æ˜¯åå­—
        
        name_parts = cols[2 : scan_index + 1]
        # æ¸…æ´—åå­—ï¼šå»æ‰å¯èƒ½æ··è¿›æ¥çš„â€œé«˜â€â€œä¸­â€â€œä½â€æˆ–è€…æ˜Ÿæ˜Ÿç¬¦å·
        raw_name = " ".join(name_parts)
        
        # æå–å®Œåå­—ï¼Œå¿…é¡»ç¡®ä¿åå­—å­˜åœ¨
        if not raw_name.strip(): 
            continue # å¦‚æœæ²¡æœ‰åå­—ï¼Œè¿™è¡Œæ•°æ®æ— æ•ˆ

        # æ„é€ äº‹ä»¶
        evt = Event()
        evt.name = f"ğŸ“Š[{country}] {raw_name}"
        
        # æ—¶é—´è§£æ
        hm = time_str.split(':')
        start_dt = datetime(
            current_date.year, current_date.month, current_date.day,
            int(hm[0]), int(hm[1]), tzinfo=pytz.timezone('Asia/Shanghai')
        )
        evt.begin = start_dt
        evt.duration = timedelta(minutes=15)
        
        evt.description = (
            f"ã€ç»æµæ•°æ®ã€‘\n"
            f"å›½å®¶: {country}\n"
            f"æŒ‡æ ‡: {raw_name}\n"
            f"----------------\n"
            f"å‰å€¼: {prev}\n"
            f"é¢„æµ‹: {forecast}\n"
            f"å…¬å¸ƒ: {actual}\n"
        )
        
        events.append(evt)
        print(f"    + [æŠ“å–æˆåŠŸ] {time_str} {country} {raw_name} | å‰:{prev} é¢„:{forecast} å…¬:{actual}")

    return events

def run_scraper():
    cal = Calendar()
    driver = get_driver()
    if not driver: exit(1)

    try:
        base_url = "https://qihuo.jin10.com/calendar.html#/"
        total_count = 0

        # éå†ç”¨æˆ·æŒ‡å®šçš„ 4 ä¸ªæ—¥æœŸ
        for date_str in TARGET_DATES:
            target_date = datetime.strptime(date_str, "%Y-%m-%d").date()
            full_url = f"{base_url}{date_str}"
            
            print(f"\n=== å¤„ç†æ—¥æœŸ: {date_str} ===")
            print(f"è®¿é—®: {full_url}")
            
            try:
                driver.get(full_url)
                # ç­‰å¾…ä¹…ä¸€ç‚¹ï¼Œå› ä¸ºå“ˆå¸Œè·³è½¬å¯èƒ½ä¸åˆ·æ–°é¡µé¢ï¼Œéœ€è¦ç»™Vueååº”æ—¶é—´
                time.sleep(8) 
                
                html = driver.page_source
                day_events = parse_day_content(html, target_date)
                
                for e in day_events:
                    cal.events.add(e)
                    total_count += 1
                    
                if not day_events:
                    print(f"    [-] è¯¥æ—¥æœŸä¸‹æœªå‘ç°ã€ç»æµæ•°æ®ä¸€è§ˆã€‘å†…å®¹")

            except Exception as e:
                print(f"    [!] é¡µé¢å¤„ç†å‡ºé”™: {e}")

    except Exception as e:
        print(f"è‡´å‘½é”™è¯¯: {traceback.format_exc()}")
    finally:
        driver.quit()

    # ä¿å­˜
    if total_count > 0:
        output_file = 'jin10_data_specific.ics'
        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(cal.serialize())
        print(f"\nå…¨éƒ¨å®Œæˆï¼ç”Ÿæˆæ–‡ä»¶: {output_file} (å…± {total_count} æ¡æ•°æ®)")
    else:
        print("\næœªæŠ“å–åˆ°ä»»ä½•æ•°æ®ã€‚")

if __name__ == "__main__":
    run_scraper()
