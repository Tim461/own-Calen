import time
import re
import os
import traceback
from datetime import datetime, timedelta
import pytz
from ics import Calendar, Event

# Selenium ç›¸å…³
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

def get_driver():
    options = Options()
    options.add_argument("--headless=new") 
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--remote-debugging-port=9222")
    options.add_argument("--window-size=1920,1080")
    # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ User-Agentï¼Œé˜²æ­¢è¢«è¯†åˆ«ä¸ºçˆ¬è™«
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    chrome_binary_path = os.environ.get("CHROME_PATH")
    if chrome_binary_path:
        options.binary_location = chrome_binary_path

    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        return driver
    except Exception as e:
        print(f"æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def parse_time_str(time_str, current_date):
    time_str = time_str.strip()
    if re.match(r'^\d{1,2}:\d{2}$', time_str):
        hm = time_str.split(':')
        start_dt = datetime(
            current_date.year, current_date.month, current_date.day,
            int(hm[0]), int(hm[1]), tzinfo=pytz.timezone('Asia/Shanghai')
        )
        return start_dt, False
    else:
        start_dt = datetime(
            current_date.year, current_date.month, current_date.day,
            0, 0, tzinfo=pytz.timezone('Asia/Shanghai')
        )
        return start_dt, True

def parse_day_content(html_content, current_date):
    events = []
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # ã€è°ƒè¯•ã€‘æ‰“å°ä¸€ä¸‹é¡µé¢æ ‡é¢˜ï¼Œç¡®è®¤é¡µé¢åŠ è½½æˆåŠŸ
    print(f"  é¡µé¢æ ‡é¢˜: {soup.title.string if soup.title else 'æ— æ ‡é¢˜'}")
    
    # ç¨å¾®æ”¾å®½åŒ¹é…æ¡ä»¶ï¼Œå»æ‰ "|", è®©æ–‡æœ¬æ›´è¿è´¯
    raw_text_check = soup.get_text()
    if "ç»æµæ•°æ®" not in raw_text_check and "è´¢ç»å¤§äº‹" not in raw_text_check:
        print("  [è­¦å‘Š] é¡µé¢ä¸­æœªå‘ç°'ç»æµæ•°æ®'æˆ–'è´¢ç»å¤§äº‹'å…³é”®è¯ï¼Œå¯èƒ½æ˜¯åçˆ¬è™«æ‹¦æˆªæˆ–åŠ è½½æœªå®Œæˆã€‚")

    mode = "UNKNOWN" 
    rows = soup.find_all(['div', 'tr', 'li'])
    processed_hashes = set()

    for i, row in enumerate(rows):
        row_str = row.get_text("|", strip=True)
        
        # ã€è°ƒè¯•ã€‘æ‰“å°å‰å‡ è¡Œçœ‹çœ‹ç»“æ„ï¼ˆä»…æ‰“å°å‰10è¡Œï¼Œé¿å…æ—¥å¿—çˆ†ç‚¸ï¼‰
        if i < 10: 
            print(f"  [Row-{i}] {row_str[:50]}...")

        # 1. æ¨¡å¼åˆ‡æ¢æ£€æµ‹ (æ”¾å®½åŒ¹é…é€»è¾‘)
        # æœ‰æ—¶å€™ "ç»æµæ•°æ®ä¸€è§ˆ" å¯èƒ½ä¼šè¢«æ ‡ç­¾éš”å¼€
        clean_row_str = row_str.replace("|", "").replace(" ", "")
        
        if "ç»æµæ•°æ®" in clean_row_str and len(clean_row_str) < 30:
            mode = "DATA"
            print("    -> åˆ‡æ¢åˆ° [ç»æµæ•°æ®] æ¨¡å¼")
            continue
        elif "è´¢ç»å¤§äº‹" in clean_row_str and len(clean_row_str) < 30:
            mode = "EVENT"
            print("    -> åˆ‡æ¢åˆ° [è´¢ç»å¤§äº‹] æ¨¡å¼")
            continue
        elif "æœŸè´§æ—¥å†" in clean_row_str or "ä¼‘å¸‚æ—¥å†" in clean_row_str:
            mode = "UNKNOWN"
            continue
            
        if mode == "UNKNOWN":
            continue

        cols = [c.strip() for c in row_str.split('|') if c.strip()]
        if not cols: continue

        # è¿‡æ»¤è¡¨å¤´
        if any(h in row_str for h in ["å‰å€¼", "é¢„æµ‹å€¼", "å…¬å¸ƒå€¼", "è¯¦æƒ…", "ä»Šå€¼", "é‡è¦æ€§"]):
            continue
        
        row_hash = hash(row_str)
        if row_hash in processed_hashes: continue
        processed_hashes.add(row_hash)

        # --- DATA ---
        if mode == "DATA":
            if len(cols) < 2: continue 
            time_str = cols[0]
            if len(time_str) > 10: continue # è¿‡æ»¤æ‚é¡¹

            name = cols[1] 
            potential_values = cols[-3:] 
            prev, forecast, actual = "--", "--", "--"
            
            if len(cols) >= 4:
                if len(potential_values) == 3:
                    prev, forecast, actual = potential_values
                elif len(potential_values) == 2:
                    prev, forecast = potential_values
            
            def is_valid_val(s): return len(s) < 20 and (any(c.isdigit() for c in s) or '--' in s or '%' in s)
            if not is_valid_val(prev): prev = "--"
            if not is_valid_val(actual): actual = "--"

            evt = Event()
            start_dt, is_fuzzy = parse_time_str(time_str, current_date)
            prefix = f"[{time_str}]" if is_fuzzy else ""
            evt.name = f"ğŸ“Š{prefix} {name}"
            evt.begin = start_dt
            evt.duration = timedelta(minutes=15)
            evt.description = f"ã€ç»æµæ•°æ®ã€‘\næ—¶é—´: {time_str}\næŒ‡æ ‡: {name}\nå…¬å¸ƒ: {actual}\né¢„æµ‹: {forecast}\nå‰å€¼: {prev}"
            events.append(evt)
            print(f"    [æ•°æ®] {time_str} | {name} | å…¬å¸ƒ:{actual}")

        # --- EVENT ---
        elif mode == "EVENT":
            if len(cols) < 3: continue
            time_str = cols[0]
            if len(time_str) > 10: continue

            country = cols[1]
            content = " ".join(cols[2:]) 

            evt = Event()
            start_dt, is_fuzzy = parse_time_str(time_str, current_date)
            prefix = f"[{time_str}]" if is_fuzzy else ""
            title_text = content[:20] + "..." if len(content) > 20 else content
            evt.name = f"ğŸ“¢{prefix}[{country}] {title_text}"
            evt.begin = start_dt
            evt.duration = timedelta(minutes=30)
            evt.description = f"ã€è´¢ç»å¤§äº‹ã€‘\næ—¶é—´: {time_str}\nåœ°åŒº: {country}\näº‹ä»¶: {content}"
            events.append(evt)
            print(f"    [å¤§äº‹] {time_str} | {country} | {title_text}")

    return events

def run_scraper():
    cal = Calendar()
    driver = get_driver()
    if not driver:
        exit(1)

    try:
        base_url = "https://qihuo.jin10.com/calendar.html#/"
        today = datetime.now(pytz.timezone('Asia/Shanghai')).date()
        
        # åªæŠ“ä»Šå¤©ä¸€å¤©ï¼Œå…ˆæµ‹è¯•èƒ½ä¸èƒ½è·‘é€š
        days_to_scrape = 1 
        total_count = 0

        for i in range(days_to_scrape):
            target_date = today + timedelta(days=i)
            date_str = target_date.strftime('%Y-%m-%d')
            full_url = f"{base_url}{date_str}"
            
            print(f"\n[{i+1}/{days_to_scrape}] æŠ“å–: {full_url}")
            
            try:
                driver.get(full_url)
                # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œé˜²æ­¢åŠ è½½è¿‡æ…¢
                time.sleep(10) 
                
                html = driver.page_source
                day_events = parse_day_content(html, target_date)
                
                for e in day_events:
                    cal.events.add(e)
                    total_count += 1
                
                if not day_events:
                    print("    (è¯¥é¡µé¢æœªæå–åˆ°äº‹ä»¶)")

            except Exception as e:
                print(f"    ! é¡µé¢å‡ºé”™: {e}")

    except Exception as e:
        print(f"å…¨å±€é”™è¯¯: {traceback.format_exc()}")
    finally:
        driver.quit()

    # ã€å¼ºåˆ¶ä¿å­˜ã€‘ï¼šå“ªæ€• total_count ä¸º 0 ä¹Ÿä¿å­˜æ–‡ä»¶ï¼Œ
    # è¿™æ ·å¯ä»¥éªŒè¯æ˜¯å¦æ˜¯ Git æäº¤çš„é—®é¢˜ï¼Œè¿˜æ˜¯çœŸçš„æ²¡æ•°æ®
    output_file = 'jin10_calendar.ics'
    with open(output_file, 'w', encoding='utf-8') as f:
        f.writelines(cal.serialize())
    
    if total_count > 0:
        print(f"\nç”ŸæˆæˆåŠŸ: {output_file} (åŒ…å« {total_count} æ¡æ•°æ®)")
    else:
        print(f"\nè­¦å‘Š: æœªæŠ“å–åˆ°ä»»ä½•æ•°æ®ï¼Œä½†å·²å¼ºåˆ¶ç”Ÿæˆç©ºæ–‡ä»¶: {output_file}")

if __name__ == "__main__":
    run_scraper()
